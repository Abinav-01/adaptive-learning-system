<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Smart Attention Monitor</title>
    <style>
        body { text-align: center; font-family: Arial; margin-top: 30px; }
        video { border: 2px solid #333; border-radius: 6px; width: 480px; }
        #status { margin-top: 10px; font-weight: bold; font-size: 18px; }
    </style>
</head>
<body>

<h2>Smart Attention Monitor</h2>

<video id="video" autoplay playsinline></video>
<div id="status" style="color: green;">Status: Detecting...</div>

<!-- Mediapipe -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

<script>
const video = document.getElementById('video');
const statusEl = document.getElementById('status');

let inattentiveCounter = 0;
const CHECK_INTERVAL = 5000; // check every 5 seconds
const MAX_INATTENTIVE_COUNT = 3; // alert after 3 consecutive inattentive checks (~15 sec)

// Initialize Mediapipe FaceMesh
const faceMesh = new FaceMesh({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
faceMesh.setOptions({
  maxNumFaces: 1,
  refineLandmarks: true,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});

// Helper: compute attention from landmarks
function computeAttention(landmarks) {
  // Head orientation
  const leftEye = landmarks[33];
  const rightEye = landmarks[263];
  const noseTip = landmarks[1];
  const eyeDistance = Math.hypot(leftEye.x - rightEye.x, leftEye.y - rightEye.y);
  const noseToEyeY = Math.abs(noseTip.y - (leftEye.y + rightEye.y)/2);
  const headFacing = (noseToEyeY / eyeDistance) < 0.4; // ratio-based threshold

  // Eye closure detection
  const leftEAR = Math.abs(landmarks[159].y - landmarks[145].y);
  const rightEAR = Math.abs(landmarks[386].y - landmarks[374].y);
  const eyesOpen = leftEAR > 0.015 && rightEAR > 0.015;

  return headFacing && eyesOpen;
}

// Callback for each frame
faceMesh.onResults(results => {
  if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
    inattentiveCounter++;
  } else {
    const attentive = computeAttention(results.multiFaceLandmarks[0]);
    inattentiveCounter = attentive ? 0 : inattentiveCounter + 1;
  }

  // Update status bar
  if (inattentiveCounter >= MAX_INATTENTIVE_COUNT) {
    statusEl.innerText = "Status: Please focus on the class!";
    statusEl.style.color = "red";
  } else {
    statusEl.innerText = "Status: Attentive ðŸ™‚";
    statusEl.style.color = "green";
  }
});

// Start camera
const camera = new Camera(video, {
  onFrame: async () => { await faceMesh.send({image: video}); },
  width: 480,
  height: 360
});
camera.start();

// Optional: periodic attention check
setInterval(() => {
  // This loop already handled in onResults; no extra code needed
}, CHECK_INTERVAL);
</script>

</body>
</html>
